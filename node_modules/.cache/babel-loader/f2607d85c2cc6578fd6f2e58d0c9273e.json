{"ast":null,"code":"import { END_OF_FILE } from \"../parser\";\n/**\n * Trait responsible abstracting over the interaction with Lexer output (Token vector).\n *\n * This could be generalized to support other kinds of lexers, e.g.\n * - Just in Time Lexing / Lexer-Less parsing.\n * - Streaming Lexer.\n */\n\nvar LexerAdapter = function () {\n  function LexerAdapter() {}\n\n  LexerAdapter.prototype.initLexerAdapter = function () {\n    this.tokVector = [];\n    this.tokVectorLength = 0;\n    this.currIdx = -1;\n  };\n\n  Object.defineProperty(LexerAdapter.prototype, \"input\", {\n    get: function () {\n      return this.tokVector;\n    },\n    set: function (newInput) {\n      if (this.selfAnalysisDone !== true) {\n        throw Error(\"Missing <performSelfAnalysis> invocation at the end of the Parser's constructor.\");\n      }\n\n      this.reset();\n      this.tokVector = newInput;\n      this.tokVectorLength = newInput.length;\n    },\n    enumerable: true,\n    configurable: true\n  }); // skips a token and returns the next token\n\n  LexerAdapter.prototype.SKIP_TOKEN = function () {\n    if (this.currIdx <= this.tokVector.length - 2) {\n      this.consumeToken();\n      return this.LA(1);\n    } else {\n      return END_OF_FILE;\n    }\n  }; // Lexer (accessing Token vector) related methods which can be overridden to implement lazy lexers\n  // or lexers dependent on parser context.\n\n\n  LexerAdapter.prototype.LA = function (howMuch) {\n    var soughtIdx = this.currIdx + howMuch;\n\n    if (soughtIdx < 0 || this.tokVectorLength <= soughtIdx) {\n      return END_OF_FILE;\n    } else {\n      return this.tokVector[soughtIdx];\n    }\n  };\n\n  LexerAdapter.prototype.consumeToken = function () {\n    this.currIdx++;\n  };\n\n  LexerAdapter.prototype.exportLexerState = function () {\n    return this.currIdx;\n  };\n\n  LexerAdapter.prototype.importLexerState = function (newState) {\n    this.currIdx = newState;\n  };\n\n  LexerAdapter.prototype.resetLexerState = function () {\n    this.currIdx = -1;\n  };\n\n  LexerAdapter.prototype.moveToTerminatedState = function () {\n    this.currIdx = this.tokVector.length - 1;\n  };\n\n  LexerAdapter.prototype.getLexerPosition = function () {\n    return this.exportLexerState();\n  };\n\n  return LexerAdapter;\n}();\n\nexport { LexerAdapter };","map":{"version":3,"sources":["/Users/mingjie.wang/Documents/Uber/MandA/demo-project/node_modules/chevrotain/lib_esm/src/parse/parser/traits/lexer_adapter.js"],"names":["END_OF_FILE","LexerAdapter","prototype","initLexerAdapter","tokVector","tokVectorLength","currIdx","Object","defineProperty","get","set","newInput","selfAnalysisDone","Error","reset","length","enumerable","configurable","SKIP_TOKEN","consumeToken","LA","howMuch","soughtIdx","exportLexerState","importLexerState","newState","resetLexerState","moveToTerminatedState","getLexerPosition"],"mappings":"AAAA,SAASA,WAAT,QAA4B,WAA5B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AACA,IAAIC,YAAY,GAAkB,YAAY;AAC1C,WAASA,YAAT,GAAwB,CACvB;;AACDA,EAAAA,YAAY,CAACC,SAAb,CAAuBC,gBAAvB,GAA0C,YAAY;AAClD,SAAKC,SAAL,GAAiB,EAAjB;AACA,SAAKC,eAAL,GAAuB,CAAvB;AACA,SAAKC,OAAL,GAAe,CAAC,CAAhB;AACH,GAJD;;AAKAC,EAAAA,MAAM,CAACC,cAAP,CAAsBP,YAAY,CAACC,SAAnC,EAA8C,OAA9C,EAAuD;AACnDO,IAAAA,GAAG,EAAE,YAAY;AACb,aAAO,KAAKL,SAAZ;AACH,KAHkD;AAInDM,IAAAA,GAAG,EAAE,UAAUC,QAAV,EAAoB;AACrB,UAAI,KAAKC,gBAAL,KAA0B,IAA9B,EAAoC;AAChC,cAAMC,KAAK,CAAC,kFAAD,CAAX;AACH;;AACD,WAAKC,KAAL;AACA,WAAKV,SAAL,GAAiBO,QAAjB;AACA,WAAKN,eAAL,GAAuBM,QAAQ,CAACI,MAAhC;AACH,KAXkD;AAYnDC,IAAAA,UAAU,EAAE,IAZuC;AAanDC,IAAAA,YAAY,EAAE;AAbqC,GAAvD,EAR0C,CAuB1C;;AACAhB,EAAAA,YAAY,CAACC,SAAb,CAAuBgB,UAAvB,GAAoC,YAAY;AAC5C,QAAI,KAAKZ,OAAL,IAAgB,KAAKF,SAAL,CAAeW,MAAf,GAAwB,CAA5C,EAA+C;AAC3C,WAAKI,YAAL;AACA,aAAO,KAAKC,EAAL,CAAQ,CAAR,CAAP;AACH,KAHD,MAIK;AACD,aAAOpB,WAAP;AACH;AACJ,GARD,CAxB0C,CAiC1C;AACA;;;AACAC,EAAAA,YAAY,CAACC,SAAb,CAAuBkB,EAAvB,GAA4B,UAAUC,OAAV,EAAmB;AAC3C,QAAIC,SAAS,GAAG,KAAKhB,OAAL,GAAee,OAA/B;;AACA,QAAIC,SAAS,GAAG,CAAZ,IAAiB,KAAKjB,eAAL,IAAwBiB,SAA7C,EAAwD;AACpD,aAAOtB,WAAP;AACH,KAFD,MAGK;AACD,aAAO,KAAKI,SAAL,CAAekB,SAAf,CAAP;AACH;AACJ,GARD;;AASArB,EAAAA,YAAY,CAACC,SAAb,CAAuBiB,YAAvB,GAAsC,YAAY;AAC9C,SAAKb,OAAL;AACH,GAFD;;AAGAL,EAAAA,YAAY,CAACC,SAAb,CAAuBqB,gBAAvB,GAA0C,YAAY;AAClD,WAAO,KAAKjB,OAAZ;AACH,GAFD;;AAGAL,EAAAA,YAAY,CAACC,SAAb,CAAuBsB,gBAAvB,GAA0C,UAAUC,QAAV,EAAoB;AAC1D,SAAKnB,OAAL,GAAemB,QAAf;AACH,GAFD;;AAGAxB,EAAAA,YAAY,CAACC,SAAb,CAAuBwB,eAAvB,GAAyC,YAAY;AACjD,SAAKpB,OAAL,GAAe,CAAC,CAAhB;AACH,GAFD;;AAGAL,EAAAA,YAAY,CAACC,SAAb,CAAuByB,qBAAvB,GAA+C,YAAY;AACvD,SAAKrB,OAAL,GAAe,KAAKF,SAAL,CAAeW,MAAf,GAAwB,CAAvC;AACH,GAFD;;AAGAd,EAAAA,YAAY,CAACC,SAAb,CAAuB0B,gBAAvB,GAA0C,YAAY;AAClD,WAAO,KAAKL,gBAAL,EAAP;AACH,GAFD;;AAGA,SAAOtB,YAAP;AACH,CA/DiC,EAAlC;;AAgEA,SAASA,YAAT","sourcesContent":["import { END_OF_FILE } from \"../parser\";\n/**\n * Trait responsible abstracting over the interaction with Lexer output (Token vector).\n *\n * This could be generalized to support other kinds of lexers, e.g.\n * - Just in Time Lexing / Lexer-Less parsing.\n * - Streaming Lexer.\n */\nvar LexerAdapter = /** @class */ (function () {\n    function LexerAdapter() {\n    }\n    LexerAdapter.prototype.initLexerAdapter = function () {\n        this.tokVector = [];\n        this.tokVectorLength = 0;\n        this.currIdx = -1;\n    };\n    Object.defineProperty(LexerAdapter.prototype, \"input\", {\n        get: function () {\n            return this.tokVector;\n        },\n        set: function (newInput) {\n            if (this.selfAnalysisDone !== true) {\n                throw Error(\"Missing <performSelfAnalysis> invocation at the end of the Parser's constructor.\");\n            }\n            this.reset();\n            this.tokVector = newInput;\n            this.tokVectorLength = newInput.length;\n        },\n        enumerable: true,\n        configurable: true\n    });\n    // skips a token and returns the next token\n    LexerAdapter.prototype.SKIP_TOKEN = function () {\n        if (this.currIdx <= this.tokVector.length - 2) {\n            this.consumeToken();\n            return this.LA(1);\n        }\n        else {\n            return END_OF_FILE;\n        }\n    };\n    // Lexer (accessing Token vector) related methods which can be overridden to implement lazy lexers\n    // or lexers dependent on parser context.\n    LexerAdapter.prototype.LA = function (howMuch) {\n        var soughtIdx = this.currIdx + howMuch;\n        if (soughtIdx < 0 || this.tokVectorLength <= soughtIdx) {\n            return END_OF_FILE;\n        }\n        else {\n            return this.tokVector[soughtIdx];\n        }\n    };\n    LexerAdapter.prototype.consumeToken = function () {\n        this.currIdx++;\n    };\n    LexerAdapter.prototype.exportLexerState = function () {\n        return this.currIdx;\n    };\n    LexerAdapter.prototype.importLexerState = function (newState) {\n        this.currIdx = newState;\n    };\n    LexerAdapter.prototype.resetLexerState = function () {\n        this.currIdx = -1;\n    };\n    LexerAdapter.prototype.moveToTerminatedState = function () {\n        this.currIdx = this.tokVector.length - 1;\n    };\n    LexerAdapter.prototype.getLexerPosition = function () {\n        return this.exportLexerState();\n    };\n    return LexerAdapter;\n}());\nexport { LexerAdapter };\n//# sourceMappingURL=lexer_adapter.js.map"]},"metadata":{},"sourceType":"module"}